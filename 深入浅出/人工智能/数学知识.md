# 基础
机器学习的数学基础
在掌握机器学习之前，理解支撑这些算法的基本数学概念非常重要。

1. 线性代数：这是理解许多算法（特别是深度学习算法）的关键。主要概念包括向量、矩阵、行列式、特征值和特征向量、向量空间以及线性变换。

2. 微积分：许多机器学习算法涉及到连续函数的优化，这需要理解导数、积分、极限和级数。多变量微积分以及梯度的概念也很重要。

3. 概率论与统计学：这些知识对于理解模型如何从数据中学习并进行预测至关重要。主要概念包括概率理论、随机变量、概率分布、期望、方差、协方差、相关性、假设检验、置信区间、最大似然估计和贝叶斯推断。
## 对数 & 指数
https://www.lianxh.cn/news/feb8ffdcb6a87.html
对数作用：
1.  缩小数据之间的绝对差异；避免个别极端值的影响
2.  尽可能满足经典线性模型假定（Classic Linear Model）
> 指数运算：$a^n = a \times a \times \cdots \times a$
> 对数运算：$\log_a b = \frac{\log b}{\log a}$
![Alt text](img/log.png)



# 线性代数
> 矩阵的本质就是线性方程式，两者是一一对应关系

[理解矩阵乘法](https://www.ruanyifeng.com/blog/2015/09/matrix-multiplication.html)
矩阵的本质就是线性方程式，两者是一一对应关系。如果从线性方程式的角度，理解矩阵乘法就毫无难度。
![Alt text](img/ju_zheng_cheng_jian.png)
核心
![Alt text](img/ju_zheng_cheng.png)

[线性回归的数学推导](https://aaaron7.github.io/blog/ml/linear-regression)


# 数据处理
## 张量
张量（tensor）在机器学习中指代多维数组，可以是标量（0维张量）、向量（1维张量）、矩阵（2维张量）或更高维的数组。在机器学习模型中，张量作为数据的基本表示和处理方式，可以进行各种数学运算和变换，例如矩阵乘法、逆矩阵、转置等。张量在深度学习和神经网络中扮演着重要角色，是神经网络中传递和处理数据的基本单位。TensorFlow 和 PyTorch 等流行的深度学习框架都支持张量的表示和操作。
